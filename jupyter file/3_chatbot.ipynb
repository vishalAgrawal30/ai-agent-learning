{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58195f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1a01b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_chat_model(\"google_genai:gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfea028",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    message:Annotated[list,add_messages]\n",
    "\n",
    "def chatbot(state:State) ->State:\n",
    "    return {\"message\":[llm.invoke(state[\"message\"])]}\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node('Chatbot_Node',chatbot)\n",
    "\n",
    "builder.add_edge(START,\"Chatbot_Node\")\n",
    "builder.add_edge(\"Chatbot_Node\",END)\n",
    "\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a95224c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image,display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19a709f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hello,i am vishal', additional_kwargs={}, response_metadata={}, id='8223571e-9419-456b-894b-866996a3cde2'),\n",
       " AIMessage(content=\"Hello Vishal, it's nice to meet you! How can I help you today?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--432891ab-3b61-4173-b6d9-61a00af99cc5-0', usage_metadata={'input_tokens': 7, 'output_tokens': 20, 'total_tokens': 27, 'input_token_details': {'cache_read': 0}})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = {\"role\":\"user\",\"content\":\"Hello,i am vishal\"}\n",
    "responce = graph.invoke({\"message\":[message]})\n",
    "\n",
    "responce[\"message\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50fbcc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini: Okay, let's create a roadmap for building your own AI Assistant model using LangGraph. This roadmap will cover the key steps, considerations, and potential challenges involved.\n",
      "\n",
      "**Overall Goal:** Build a LangGraph-powered AI Assistant capable of handling user requests, leveraging various tools (like search, calculators, databases, etc.), and providing helpful, context-aware responses.\n",
      "\n",
      "**Roadmap:**\n",
      "\n",
      "**Phase 1: Foundational Setup and Core Functionality**\n",
      "\n",
      "1.  **Environment Setup & Dependencies:**\n",
      "    *   **Python Environment:**  Use a virtual environment (e.g., `venv`, `conda`) to manage dependencies.\n",
      "    *   **Install LangChain and LangGraph:**\n",
      "        ```bash\n",
      "        pip install langchain langchain-core langchain-community langgraph\n",
      "        # Install necessary tools and dependencies as needed (e.g., google-search-results, wikipedia)\n",
      "        ```\n",
      "    *   **API Keys:**  Obtain API keys for any external services you plan to use (e.g., OpenAI, Google Search, etc.). Store these securely (environment variables are recommended).\n",
      "\n",
      "2.  **Define the Agent's Core Purpose and Capabilities:**\n",
      "    *   **Identify Target Users & Use Cases:**  Who is this assistant for? What problems will it solve?  Be specific. Examples:\n",
      "        *   \"A research assistant for students, helping them find information and summarize articles.\"\n",
      "        *   \"A personal assistant for scheduling appointments and managing tasks.\"\n",
      "        *   \"A code assistant for debugging and generating code snippets.\"\n",
      "    *   **List Desired Capabilities:**  What can the agent *do*?\n",
      "        *   Answer questions (factual, conceptual)\n",
      "        *   Summarize text\n",
      "        *   Translate languages\n",
      "        *   Perform calculations\n",
      "        *   Search the web\n",
      "        *   Access and manipulate data from a database\n",
      "        *   Write and execute code\n",
      "        *   Schedule events\n",
      "        *   Control external systems (e.g., IOT devices)\n",
      "\n",
      "3.  **Choose an LLM (Language Model):**\n",
      "    *   **Options:**  OpenAI's GPT models (GPT-3.5, GPT-4), open-source models like Llama 2, Mistral, or others available through Hugging Face.\n",
      "    *   **Considerations:**  Cost, performance, context window size, and ease of use.  Start with a more cost-effective model during development and upgrade later if needed.  GPT-3.5 Turbo is a good starting point.\n",
      "    *   **Set up LLM Access:**  Configure LangChain to use your chosen LLM, providing the necessary API key or connection details.\n",
      "\n",
      "4.  **Implement Basic Tool Usage:**\n",
      "    *   **Select Initial Tools:** Start with 1-2 essential tools relevant to your agent's purpose. Examples:\n",
      "        *   `WikipediaQueryRun` (for answering factual questions)\n",
      "        *   `GoogleSearchRun` (for general web search)\n",
      "        *   `Calculator` (for math calculations)\n",
      "        *   `PythonREPLTool` (for executing Python code - use with caution!)\n",
      "    *   **Create LangChain Tools:**  Wrap the tools using LangChain's `Tool` interface. This involves defining the tool's name, description, and a function that executes the tool.\n",
      "    *   **Example (Calculator):**\n",
      "        ```python\n",
      "        from langchain_community.utilities import SerpAPIWrapper\n",
      "        from langchain_core.tools import Tool\n",
      "\n",
      "        def multiply(a: float, b: float) -> float:\n",
      "            \"\"\"Multiply two numbers.\"\"\"\n",
      "            return a * b\n",
      "\n",
      "        calculator_tool = Tool(\n",
      "            name=\"Calculator\",\n",
      "            func=multiply,\n",
      "            description=\"Useful for when you need to multiply two numbers together. The input to this tool should be two numbers, each seperated by a space.\"\n",
      "        )\n",
      "        ```\n",
      "    *   **Example (Search):**\n",
      "        ```python\n",
      "        from langchain_community.utilities import SerpAPIWrapper\n",
      "        from langchain_core.tools import Tool\n",
      "\n",
      "        search = SerpAPIWrapper()\n",
      "        search_tool = Tool(\n",
      "            name=\"Search\",\n",
      "            func=search.run,\n",
      "            description=\"Useful for when you need to answer questions about current events. You should ask targeted questions.\"\n",
      "        )\n",
      "        ```\n",
      "\n",
      "5.  **Design the Agent's State and Nodes:**\n",
      "    *   **State:**  The `AgentState` in LangGraph holds the data that the agent uses and updates as it interacts.  At a minimum, it will likely include:\n",
      "        *   `messages`: A list of messages representing the conversation history.\n",
      "        *   `intermediate_steps`: A list of tuples containing the agent's action and the output of the tool used.\n",
      "    *   **Nodes:**  The core logic of your agent lives in nodes. Common types:\n",
      "        *   **LLM Node:**  This node uses the LLM to decide on the next action (e.g., generate a response or choose a tool).\n",
      "        *   **Tool Node:**  This node executes a selected tool and returns the result.\n",
      "        *   **Conditional Node:** This node determines the next node to visit based on the current state (e.g., \"If the LLM chose a tool, go to the Tool Node. If the LLM wants to respond to the user, go to the End Node.\").\n",
      "\n",
      "6.  **Implement the Basic Graph Structure:**\n",
      "    *   **Create the Graph:** Use `langgraph.GraphState` and `langgraph.Graph` to define the graph's structure.\n",
      "    *   **Define Nodes:**  Create the LLM node, tool node(s), and any conditional nodes.\n",
      "    *   **Connect Nodes:**  Use `graph.add_node()` and `graph.add_edge()` (or `graph.add_conditional_edges()`) to define the flow of execution.  The basic flow is usually: User Input -> LLM Node -> (Tool Node OR End Node) -> LLM Node (if using a tool) -> ... -> End Node.\n",
      "    *   **Example (Simplified):**\n",
      "\n",
      "        ```python\n",
      "        from typing import TypedDict, List, Dict, Any\n",
      "        import langchain_core.messages as lc\n",
      "\n",
      "        from langgraph.graph import StateGraph, END\n",
      "        import langgraph.prebuilt as prebuilt\n",
      "\n",
      "        class AgentState(TypedDict):\n",
      "            messages: List[lc.BaseMessage]\n",
      "            intermediate_steps: List[Dict[str, Any]]\n",
      "            tools: List[Tool]\n",
      "\n",
      "        def route_step(state):\n",
      "            messages = state['messages']\n",
      "            last_message = messages[-1]\n",
      "            if \"tool_calls\" in last_message.content:\n",
      "                return \"use_tool\"\n",
      "            else:\n",
      "                return \"respond\"\n",
      "\n",
      "        def create_graph(llm, tools):\n",
      "            # Initialize graph\n",
      "            graph = StateGraph(AgentState)\n",
      "\n",
      "            # Add nodes\n",
      "            graph.add_node(\"agent\", prebuilt.create_agent_executor(llm, tools))\n",
      "            graph.add_node(\"use_tool\", prebuilt.create_tool_executor(tools))\n",
      "            graph.add_node(\"respond\", lambda state: {\"messages\": [lc.AIMessage(content=\"I don't know.\")]})\n",
      "\n",
      "            # Add edges\n",
      "            graph.add_edge(\"agent\", \"route\")\n",
      "            graph.add_edge(\"use_tool\", \"agent\")\n",
      "            graph.add_conditional_edges(\"route\", route_step, {\"use_tool\": \"use_tool\", \"respond\": END})\n",
      "\n",
      "            # Compile\n",
      "            return graph.compile()\n",
      "        ```\n",
      "\n",
      "7.  **Implement Agent Logic in the LLM Node:**\n",
      "    *   **Prompt Engineering:**  Craft a prompt that instructs the LLM on how to:\n",
      "        *   Analyze the user's input.\n",
      "        *   Decide whether to use a tool or respond directly.\n",
      "        *   If using a tool, select the appropriate tool and format the input correctly.\n",
      "        *   If responding directly, generate a helpful and informative response.\n",
      "    *   **Output Parsing:**  Parse the LLM's output to extract the tool selection (if any) and the tool input.  LangChain provides output parsers to help with this.\n",
      "    *   **Example (Simplified Prompt):**\n",
      "\n",
      "        ```python\n",
      "        from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
      "        from langchain_core.runnables import chain\n",
      "\n",
      "        def create_agent_executor(llm, tools):\n",
      "            prompt = ChatPromptTemplate.from_messages([\n",
      "                (\"system\", \"You are a helpful assistant. Use the tools provided to answer the user's questions.\"),\n",
      "                MessagesPlaceholder(variable_name=\"messages\"),\n",
      "                MessagesPlaceholder(variable_name=\"intermediate_steps\"),\n",
      "            ])\n",
      "\n",
      "            return prompt | llm\n",
      "        ```\n",
      "\n",
      "8.  **Test and Iterate:**\n",
      "    *   **Simple Test Cases:**  Start with simple, straightforward questions to test the basic functionality.\n",
      "    *   **Debugging:**  Use logging and print statements to track the flow of execution and identify errors.  LangGraph's tracing capabilities can be very helpful.\n",
      "    *   **Prompt Refinement:**  Iterate on the prompt to improve the agent's decision-making and response quality.  Experiment with different prompt formats and instructions.\n",
      "\n",
      "**Phase 2: Advanced Features and Refinement**\n",
      "\n",
      "1.  **Implement Memory (Conversation History):**\n",
      "    *   **Choose a Memory Type:**  LangChain offers various memory types (e.g., `ConversationBufferMemory`, `ConversationSummaryMemory`, `ConversationTokenBufferMemory`).  `ConversationBufferMemory` is a good starting point.\n",
      "    *   **Integrate Memory into the State:**  Add the memory object to the `AgentState`.\n",
      "    *   **Update Memory in the Graph:**  Add a node to update the memory after each interaction (e.g., store the user's input and the agent's response).\n",
      "    *   **Pass Memory to the LLM Node:**  Include the conversation history from the memory in the LLM's prompt.\n",
      "\n",
      "2.  **Implement More Complex Tool Usage:**\n",
      "    *   **Add More Tools:**  Expand the agent's capabilities by adding more tools relevant to its purpose.\n",
      "    *   **Tool Chaining:**  Enable the agent to use multiple tools in sequence to answer a question (e.g., search for information, then summarize the results).  This often requires more sophisticated prompt engineering and output parsing.\n",
      "    *   **Custom Tools:**  Create your own custom tools to access specific data sources or perform specialized tasks.\n",
      "\n",
      "3.  **Improve Agent Decision-Making:**\n",
      "    *   **Refine the Prompt:**  Continuously refine the prompt to improve the agent's ability to choose the right tool, format the input correctly, and generate helpful responses.\n",
      "    *   **Add Reasoning Steps:**  Instruct the agent to explicitly state its reasoning process before choosing a tool or responding.  This can improve transparency and help you debug the agent's behavior.\n",
      "    *   **Implement a ReAct-Style Loop:**  The ReAct (Reasoning and Acting) framework encourages the agent to first *reason* about the task, then *act* by using a tool, and then *observe* the result.  This can significantly improve performance on complex tasks.\n",
      "\n",
      "4.  **Implement Error Handling and Fallback Mechanisms:**\n",
      "    *   **Handle Tool Errors:**  Gracefully handle errors that occur when using tools (e.g., invalid input, API errors).  Provide informative error messages to the user.\n",
      "    *   **Implement Fallback Responses:**  If the agent is unable to answer a question, provide a helpful fallback response (e.g., \"I'm sorry, I don't know the answer to that question.  Could you rephrase it?\").\n",
      "    *   **Implement a \"Help\" Command:**  Allow the user to ask for help or instructions on how to use the agent.\n",
      "\n",
      "5.  **Implement User Feedback Mechanisms:**\n",
      "    *   **Allow Users to Rate Responses:**  Collect user feedback on the quality of the agent's responses (e.g., thumbs up/down).\n",
      "    *   **Use Feedback to Improve the Agent:**  Use the collected feedback to identify areas where the agent can be improved (e.g., by refining the prompt, adding more tools, or improving error handling).  Consider using techniques like Reinforcement Learning from Human Feedback (RLHF) for advanced training.\n",
      "\n",
      "6.  **Evaluate Performance:**\n",
      "    *   **Define Metrics:**  Establish metrics to measure the agent's performance (e.g., accuracy, relevance, helpfulness, completion rate).\n",
      "    *   **Create a Test Dataset:**  Create a dataset of questions and tasks to evaluate the agent's performance.\n",
      "    *   **Regularly Evaluate the Agent:**  Regularly evaluate the agent's performance and track progress over time.\n",
      "\n",
      "**Phase 3: Deployment and Scaling**\n",
      "\n",
      "1.  **Choose a Deployment Platform:**\n",
      "    *   **Options:**  Web application (using Flask, Django, Streamlit), API endpoint (using FastAPI), serverless function (using AWS Lambda, Google Cloud Functions), or a dedicated server.\n",
      "    *   **Considerations:**  Scalability, cost, ease of deployment, and security.\n",
      "\n",
      "2.  **Implement a User Interface:**\n",
      "    *   **Options:**  Chat interface (using Streamlit, Gradio, or a custom web application), command-line interface, or a voice interface.\n",
      "    *   **Considerations:**  User experience, accessibility, and integration with the deployment platform.\n",
      "\n",
      "3.  **Implement Authentication and Authorization:**\n",
      "    *   **Protect the API:**  Implement authentication and authorization to protect the API from unauthorized access.\n",
      "    *   **User Management:**  Implement user management features (e.g., user registration, login, password reset).\n",
      "\n",
      "4.  **Monitor and Maintain the Agent:**\n",
      "    *   **Logging:**  Implement comprehensive logging to track the agent's activity and identify errors.\n",
      "    *   **Monitoring:**  Monitor the agent's performance and resource usage.\n",
      "    *   **Regular Updates:**  Regularly update the agent with new features, bug fixes, and security patches.\n",
      "\n",
      "**Key Considerations & Challenges:**\n",
      "\n",
      "*   **Prompt Engineering is Crucial:** The quality of your prompts will heavily influence the agent's performance.  Expect to spend a significant amount of time iterating on your prompts.\n",
      "*   **Tool Selection and Usage:**  Choosing the right tools and teaching the agent how to use them effectively is essential.\n",
      "*   **Context Window Limits:**  LLMs have context window limits, which can restrict the amount of information the agent can process at once.  Consider using techniques like summarization or retrieval to manage long conversations.\n",
      "*   **Hallucinations:**  LLMs can sometimes generate incorrect or nonsensical information.  Implement mechanisms to detect and mitigate hallucinations.\n",
      "*   **Security:**  Be mindful of security risks when using external tools or APIs.  Sanitize user input and protect API keys.\n",
      "*   **Cost:**  Running LLMs can be expensive.  Monitor your API usage and consider using cost-optimization techniques.\n",
      "*   **Bias:**  LLMs can be biased based on the data they were trained on.  Be aware of potential biases and take steps to mitigate them.\n",
      "\n",
      "**Example LangGraph Code (Illustrative - Needs Adaptation):**\n",
      "\n",
      "```python\n",
      "from typing import TypedDict, List, Dict, Any\n",
      "import langchain_core.messages as lc\n",
      "\n",
      "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
      "from langchain_core.runnables import chain\n",
      "from langchain_core.tools import Tool\n",
      "\n",
      "from langgraph.graph import StateGraph, END\n",
      "import langgraph.prebuilt as prebuilt\n",
      "from langchain_community.utilities import SerpAPIWrapper\n",
      "\n",
      "class AgentState(TypedDict):\n",
      "    messages: List[lc.BaseMessage]\n",
      "    intermediate_steps: List[Dict[str, Any]]\n",
      "    tools: List[Tool]\n",
      "\n",
      "def route_step(state):\n",
      "    messages = state['messages']\n",
      "    last_message = messages[-1]\n",
      "    if \"tool_calls\" in last_message.content:\n",
      "        return \"use_tool\"\n",
      "    else:\n",
      "        return \"respond\"\n",
      "\n",
      "def create_graph(llm, tools):\n",
      "    # Initialize graph\n",
      "    graph = StateGraph(AgentState)\n",
      "\n",
      "    # Add nodes\n",
      "    graph.add_node(\"agent\", prebuilt.create_agent_executor(llm, tools))\n",
      "    graph.add_node(\"use_tool\", prebuilt.create_tool_executor(tools))\n",
      "    graph.add_node(\"respond\", lambda state: {\"messages\": [lc.AIMessage(content=\"I don't know.\")]})\n",
      "\n",
      "    # Add edges\n",
      "    graph.add_edge(\"agent\", \"route\")\n",
      "    graph.add_edge(\"use_tool\", \"agent\")\n",
      "    graph.add_conditional_edges(\"route\", route_step, {\"use_tool\": \"use_tool\", \"respond\": END})\n",
      "\n",
      "    # Compile\n",
      "    return graph.compile()\n",
      "\n",
      "def create_agent_executor(llm, tools):\n",
      "    prompt = ChatPromptTemplate.from_messages([\n",
      "        (\"system\", \"You are a helpful assistant. Use the tools provided to answer the user's questions.\"),\n",
      "        MessagesPlaceholder(variable_name=\"messages\"),\n",
      "        MessagesPlaceholder(variable_name=\"intermediate_steps\"),\n",
      "    ])\n",
      "\n",
      "    return prompt | llm\n",
      "\n",
      "# Example Usage\n",
      "from langchain_openai import ChatOpenAI\n",
      "import os\n",
      "\n",
      "# Set up your OpenAI API key\n",
      "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\"\n",
      "os.environ[\"SERPAPI_API_KEY\"] = \"YOUR_SERPAPI_API_KEY\"\n",
      "\n",
      "# Initialize the LLM\n",
      "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", streaming=True)\n",
      "\n",
      "search = SerpAPIWrapper()\n",
      "search_tool = Tool(\n",
      "    name=\"Search\",\n",
      "    func=search.run,\n",
      "    description=\"Useful for when you need to answer questions about current events. You should ask targeted questions.\"\n",
      ")\n",
      "\n",
      "# Define the tools\n",
      "tools = [search_tool]\n",
      "\n",
      "# Create the LangGraph\n",
      "graph = create_graph(llm, tools)\n",
      "\n",
      "# Run the graph\n",
      "inputs = {\"messages\": [lc.HumanMessage(content=\"What is the capital of France?\")]}\n",
      "for output in graph.stream(inputs):\n",
      "    for key, value in output.items():\n",
      "        print(f\"Node '{key}':\")\n",
      "        print(value)\n",
      "    print(\"\\n---\\n\")\n",
      "```\n",
      "\n",
      "**Next Steps:**\n",
      "\n",
      "1.  **Start Small:** Begin with a very simple agent that can perform one or two basic tasks.\n",
      "2.  **Experiment and Iterate:**  Don't be afraid to experiment with different LLMs, prompts, and tools.\n",
      "3.  **Consult the LangChain and LangGraph Documentation:**  The official documentation is your best resource for learning about the available features and options.\n",
      "4.  **Join the LangChain Community:**  The LangChain community is a great place to ask questions and get help from other developers.\n",
      "\n",
      "This roadmap provides a comprehensive guide to building your own AI Assistant using LangGraph. Remember to break down the project into smaller, manageable tasks, and don't be afraid to ask for help when you need it. Good luck!\n",
      "Gemini: Yes, you absolutely can access your HRMS data within your LangGraph-powered AI Assistant. However, it requires careful planning and implementation to ensure security, data privacy, and proper integration. Here's how you can approach it:\n",
      "\n",
      "**1. Identify Your HRMS API/Data Access Method:**\n",
      "\n",
      "*   **Does your HRMS offer an API?** This is the ideal scenario. Most modern HRMS systems (e.g., Workday, BambooHR, ADP Workforce Now, Oracle HCM Cloud, SAP SuccessFactors) provide REST APIs that allow you to programmatically access and manipulate data. Look for API documentation specifying available endpoints, authentication methods, and data formats.\n",
      "*   **Can you access the HRMS database directly?**  This is generally *not* recommended due to security and data integrity concerns.  Direct database access bypasses the HRMS system's built-in security and validation mechanisms.  Only consider this if an API is absolutely not available and you have explicit permission from your organization's security and IT teams.  You'll need the database connection details (host, port, database name, username, password).\n",
      "*   **Can you generate reports that can be parsed?** If an API is not available, some HRMS systems allow you to generate reports in formats like CSV, Excel, or JSON.  You can then write code to parse these reports and extract the necessary data.  This is less ideal than an API but can be a viable workaround.\n",
      "\n",
      "**2. Authentication and Authorization:**\n",
      "\n",
      "*   **API Keys/Credentials:**  If using an API, you'll need API keys or credentials to authenticate your requests.  Store these securely using environment variables or a secrets management system (e.g., AWS Secrets Manager, HashiCorp Vault). *Never* hardcode API keys directly into your code.\n",
      "*   **OAuth 2.0:**  Some HRMS systems use OAuth 2.0 for authentication.  This involves a more complex process of obtaining an access token from the HRMS system.  LangChain and other libraries provide support for OAuth 2.0.\n",
      "*   **Role-Based Access Control (RBAC):**  Your HRMS likely has RBAC to control which users can access which data.  Your AI assistant should respect these access controls.  You'll need to ensure that the API credentials used by the assistant have the appropriate permissions.\n",
      "\n",
      "**3. Create a Custom Tool for HRMS Access:**\n",
      "\n",
      "*   **Define the Tool's Purpose:**  What specific HRMS data will the tool access? Examples:\n",
      "    *   \"Get employee information by ID.\"\n",
      "    *   \"Search for employees by name.\"\n",
      "    *   \"Retrieve employee's performance review.\"\n",
      "    *   \"Get an employee's manager.\"\n",
      "    *   \"Retrieve available vacation days.\"\n",
      "*   **Implement the Tool Function:**  Write a Python function that uses the HRMS API (or other data access method) to retrieve the requested data.  Handle API errors gracefully.\n",
      "*   **Wrap the Function as a LangChain Tool:**  Use the `Tool` class from `langchain_core.tools` to wrap your HRMS access function.  Provide a clear name and description for the tool.\n",
      "\n",
      "**Example (Illustrative - Adapt to Your HRMS):**\n",
      "\n",
      "```python\n",
      "from langchain_core.tools import Tool\n",
      "import requests\n",
      "import os\n",
      "\n",
      "# Replace with your HRMS API endpoint and API key\n",
      "HRMS_API_URL = \"https://your-hrms-api.com\"\n",
      "HRMS_API_KEY = os.environ.get(\"HRMS_API_KEY\")\n",
      "\n",
      "def get_employee_info(employee_id: str) -> str:\n",
      "    \"\"\"Retrieves employee information from the HRMS system.\"\"\"\n",
      "    try:\n",
      "        headers = {\"Authorization\": f\"Bearer {HRMS_API_KEY}\"}\n",
      "        response = requests.get(f\"{HRMS_API_URL}/employees/{employee_id}\", headers=headers)\n",
      "        response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
      "        employee_data = response.json()\n",
      "        return str(employee_data)  # Convert to string for LangChain\n",
      "    except requests.exceptions.RequestException as e:\n",
      "        return f\"Error retrieving employee information: {e}\"\n",
      "\n",
      "hrms_tool = Tool(\n",
      "    name=\"GetEmployeeInfo\",\n",
      "    func=get_employee_info,\n",
      "    description=\"Useful for retrieving employee information from the HRMS system. Input should be the employee's ID.\",\n",
      ")\n",
      "```\n",
      "\n",
      "**4. Integrate the HRMS Tool into Your LangGraph:**\n",
      "\n",
      "*   **Add the Tool to the Tool List:**  Include the `hrms_tool` in the list of tools available to your agent.\n",
      "*   **Prompt Engineering:**  Update your prompt to instruct the LLM to use the `GetEmployeeInfo` tool when the user asks a question about an employee.\n",
      "*   **Test and Refine:**  Test the agent with questions that require HRMS data.  Refine the prompt and the tool function as needed.\n",
      "\n",
      "**5. Security Considerations (Critical):**\n",
      "\n",
      "*   **Principle of Least Privilege:**  Grant the API credentials used by the assistant only the minimum necessary permissions to access the required HRMS data.\n",
      "*   **Data Masking/Redaction:**  Be careful not to expose sensitive HRMS data (e.g., salary, performance reviews) to unauthorized users.  Consider masking or redacting sensitive data in the agent's responses.\n",
      "*   **Input Validation:**  Validate user input to prevent malicious attacks (e.g., SQL injection, command injection).\n",
      "*   **Logging and Auditing:**  Log all HRMS data access events for auditing purposes.\n",
      "*   **Regular Security Reviews:**  Conduct regular security reviews of your AI assistant to identify and address potential vulnerabilities.\n",
      "*   **Compliance:** Ensure compliance with all relevant data privacy regulations (e.g., GDPR, CCPA).  Consult with your organization's legal and compliance teams.\n",
      "\n",
      "**6. Data Privacy Considerations:**\n",
      "\n",
      "*   **Transparency:**  Be transparent with users about how their data is being used.\n",
      "*   **Data Minimization:**  Only collect and process the minimum amount of data necessary.\n",
      "*   **Data Retention:**  Establish a data retention policy and delete data when it is no longer needed.\n",
      "*   **User Consent:**  Obtain user consent before accessing or processing their HRMS data.\n",
      "*   **Anonymization/Pseudonymization:** Consider anonymizing or pseudonymizing HRMS data to protect user privacy.\n",
      "\n",
      "**7. Scalability and Performance:**\n",
      "\n",
      "*   **API Rate Limits:**  Be aware of the HRMS API's rate limits and implement mechanisms to avoid exceeding them (e.g., caching, request throttling).\n",
      "*   **Caching:**  Cache frequently accessed HRMS data to improve performance and reduce API calls.\n",
      "*   **Asynchronous Processing:**  Use asynchronous processing to handle long-running HRMS API calls.\n",
      "\n",
      "**Example Updated Graph Code (Illustrative):**\n",
      "\n",
      "```python\n",
      "from typing import TypedDict, List, Dict, Any\n",
      "import langchain_core.messages as lc\n",
      "\n",
      "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
      "from langchain_core.runnables import chain\n",
      "from langchain_core.tools import Tool\n",
      "\n",
      "from langgraph.graph import StateGraph, END\n",
      "import langgraph.prebuilt as prebuilt\n",
      "from langchain_community.utilities import SerpAPIWrapper\n",
      "from langchain_openai import ChatOpenAI\n",
      "import os\n",
      "import requests\n",
      "\n",
      "# Replace with your HRMS API endpoint and API key\n",
      "HRMS_API_URL = \"https://your-hrms-api.com\"  # Replace with your actual URL\n",
      "HRMS_API_KEY = os.environ.get(\"HRMS_API_KEY\")  # Ensure this is set\n",
      "\n",
      "class AgentState(TypedDict):\n",
      "    messages: List[lc.BaseMessage]\n",
      "    intermediate_steps: List[Dict[str, Any]]\n",
      "    tools: List[Tool]\n",
      "\n",
      "def route_step(state):\n",
      "    messages = state['messages']\n",
      "    last_message = messages[-1]\n",
      "    if \"tool_calls\" in last_message.content:\n",
      "        return \"use_tool\"\n",
      "    else:\n",
      "        return \"respond\"\n",
      "\n",
      "def create_graph(llm, tools):\n",
      "    # Initialize graph\n",
      "    graph = StateGraph(AgentState)\n",
      "\n",
      "    # Add nodes\n",
      "    graph.add_node(\"agent\", prebuilt.create_agent_executor(llm, tools))\n",
      "    graph.add_node(\"use_tool\", prebuilt.create_tool_executor(tools))\n",
      "    graph.add_node(\"respond\", lambda state: {\"messages\": [lc.AIMessage(content=\"I don't know.\")]})\n",
      "\n",
      "    # Add edges\n",
      "    graph.add_edge(\"agent\", \"route\")\n",
      "    graph.add_edge(\"use_tool\", \"agent\")\n",
      "    graph.add_conditional_edges(\"route\", route_step, {\"use_tool\": \"use_tool\", \"respond\": END})\n",
      "\n",
      "    # Compile\n",
      "    return graph.compile()\n",
      "\n",
      "def create_agent_executor(llm, tools):\n",
      "    prompt = ChatPromptTemplate.from_messages([\n",
      "        (\"system\", \"You are a helpful assistant. Use the tools provided to answer the user's questions.  You have access to HRMS data, use this wisely and respectfully.\"),\n",
      "        MessagesPlaceholder(variable_name=\"messages\"),\n",
      "        MessagesPlaceholder(variable_name=\"intermediate_steps\"),\n",
      "    ])\n",
      "\n",
      "    return prompt | llm\n",
      "\n",
      "def get_employee_info(employee_id: str) -> str:\n",
      "    \"\"\"Retrieves employee information from the HRMS system.\"\"\"\n",
      "    if not HRMS_API_KEY:\n",
      "        return \"Error: HRMS_API_KEY is not set.\"\n",
      "    try:\n",
      "        headers = {\"Authorization\": f\"Bearer {HRMS_API_KEY}\"}\n",
      "        response = requests.get(f\"{HRMS_API_URL}/employees/{employee_id}\", headers=headers)\n",
      "        response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
      "        employee_data = response.json()\n",
      "        return str(employee_data)  # Convert to string for LangChain\n",
      "    except requests.exceptions.RequestException as e:\n",
      "        return f\"Error retrieving employee information: {e}\"\n",
      "\n",
      "hrms_tool = Tool(\n",
      "    name=\"GetEmployeeInfo\",\n",
      "    func=get_employee_info,\n",
      "    description=\"Useful for retrieving employee information from the HRMS system. Input should be the employee's ID.\",\n",
      ")\n",
      "\n",
      "# Example Usage\n",
      "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"  # Replace with your actual key\n",
      "os.environ[\"SERPAPI_API_KEY\"] = \"YOUR_SERPAPI_API_KEY\" # Replace with your actual key\n",
      "# Initialize the LLM\n",
      "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", streaming=True)\n",
      "\n",
      "search = SerpAPIWrapper()\n",
      "search_tool = Tool(\n",
      "    name=\"Search\",\n",
      "    func=search.run,\n",
      "    description=\"Useful for when you need to answer questions about current events. You should ask targeted questions.\"\n",
      ")\n",
      "\n",
      "# Define the tools\n",
      "tools = [search_tool, hrms_tool]\n",
      "\n",
      "# Create the LangGraph\n",
      "graph = create_graph(llm, tools)\n",
      "\n",
      "# Example question to trigger the HRMS tool\n",
      "inputs = {\"messages\": [lc.HumanMessage(content=\"What is the information for employee id 12345?\")]}\n",
      "\n",
      "# Run the graph\n",
      "for output in graph.stream(inputs):\n",
      "    for key, value in output.items():\n",
      "        print(f\"Node '{key}':\")\n",
      "        print(value)\n",
      "    print(\"\\n---\\n\")\n",
      "```\n",
      "\n",
      "**Important Notes:**\n",
      "\n",
      "*   **Start with a Small Scope:** Begin by accessing only a limited subset of HRMS data. Gradually expand the scope as you gain confidence in your implementation.\n",
      "*   **Test Thoroughly:** Test your AI assistant extensively to ensure that it is accessing HRMS data correctly and securely.\n",
      "*   **Consult with Experts:** Consult with your organization's security, IT, legal, and compliance teams to ensure that your implementation meets all applicable requirements.\n",
      "\n",
      "Accessing HRMS data within your AI assistant can be a powerful way to enhance its capabilities. However, it is crucial to prioritize security, data privacy, and compliance. By following the steps outlined above, you can build a secure and responsible AI assistant that provides valuable insights from your HRMS data. Remember to adapt the code examples to your specific HRMS system and security requirements. Good luck!\n",
      "Gemini: Goodbye! ðŸ‘‹\n"
     ]
    }
   ],
   "source": [
    "state = None\n",
    "while True:\n",
    "    in_message = input(\"you\")\n",
    "    if in_message.lower() in [\"quit\", \"exit\", \"bye\", \"goodbye\", \"see you later\"]:\n",
    "        print(\"Gemini: Goodbye! ðŸ‘‹\")\n",
    "        break\n",
    "    if state is None:\n",
    "        state:State = {\n",
    "            \"message\":[{\"role\":\"user\",\"content\":in_message}]\n",
    "        }\n",
    "    else:\n",
    "        state[\"message\"].append({\"role\":\"user\",\"content\":in_message})\n",
    "\n",
    "    state = graph.invoke(state)\n",
    "    print(\"Gemini:\",state[\"message\"][-1].content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
